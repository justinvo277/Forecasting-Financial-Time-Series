{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8749145,"sourceType":"datasetVersion","datasetId":5254611}],"dockerImageVersionId":30498,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport os, math\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n\nimport tensorflow as tf ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-21T14:01:43.909011Z","iopub.execute_input":"2024-06-21T14:01:43.909826Z","iopub.status.idle":"2024-06-21T14:01:52.005708Z","shell.execute_reply.started":"2024-06-21T14:01:43.909794Z","shell.execute_reply":"2024-06-21T14:01:52.004934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_Dataframes(data_path:str=None, type_file:str=\"csv\") -> pd.DataFrame:\n\n    '''\n    data_path: Dataset path.\n    type: File type dataset, for example: data.csv, data.xlsx, ...\n    '''\n\n    if data_path is None or os.path.exists(data_path) == False:\n        print(\"The path of dataset does not exist. Please check again !!\")\n    else:\n\n        df = None\n        if type_file == \"csv\":\n            df = pd.read_csv(data_path)\n        elif type_file == \"xlsx\":\n            df = pd.read_excel(data_path)\n        else:\n            print(\"Opening this file type is not supported !!\")\n\n        column_names = [\"Tên\", \"Ngày\", 'Đóng cửa', 'Điều chỉnh', \"Thay đổi\", \"Thay đổi 1\", \"%\", \n        'Khối lượng (Khớp lệnh)', 'Giá trị (Khớp lệnh)', 'Khối lượng (Thỏa thuận)', 'Giá trị (Thỏa thuận)', \n        'Mở cửa', 'Cao nhất', 'Thấp nhất']\n\n        new_column_names = df.iloc[0]\n        df = df[1:]\n        df.columns = new_column_names\n        df.reset_index(drop=True, inplace=True)\n        df.columns = column_names\n\n        for name in df.columns:\n            if name not in [\"Tên\", \"Ngày\", 'Điều chỉnh', \"Thay đổi\", \"Thay đổi 1\", \"%\"]:\n                df[name] =  pd.to_numeric(df[name], errors='coerce')\n        return df","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:01:52.007162Z","iopub.execute_input":"2024-06-21T14:01:52.007706Z","iopub.status.idle":"2024-06-21T14:01:52.016833Z","shell.execute_reply.started":"2024-06-21T14:01:52.007680Z","shell.execute_reply":"2024-06-21T14:01:52.015946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Load Dataset\ndata_raw = format_Dataframes(\"/kaggle/input/fpt-stock/FPT_stock.xlsx\",'xlsx')\ndata_raw.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:01:52.017895Z","iopub.execute_input":"2024-06-21T14:01:52.018154Z","iopub.status.idle":"2024-06-21T14:01:54.352470Z","shell.execute_reply.started":"2024-06-21T14:01:52.018108Z","shell.execute_reply":"2024-06-21T14:01:54.351377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess Data","metadata":{}},{"cell_type":"code","source":"def preprocessing_dataframe(dataFrame: pd.DataFrame, fillna: str=\"mean\", scale: str=\"std\") -> pd.DataFrame:\n\n    '''\n    dataFrame: A data frame is data after reading from a csv file and having run it through the format_Dataframes() function.\n    fillna: Type of fill data NaN, Null or None; [None, Zero, Mean].\n    scale: Type of scale; [MinMaxScaler, StandardScaler]\n    '''\n\n    dataFrame.drop(columns=['Điều chỉnh', 'Thay đổi', 'Thay đổi 1', '%'], inplace=True)\n    scaler = None\n\n    if fillna == \"zero\":\n        float_columns = dataFrame.select_dtypes(include=['float']).columns\n        dataFrame[float_columns] = dataFrame[float_columns].fillna(0)\n        int_columns = dataFrame.select_dtypes(include=['int']).columns\n        dataFrame[int_columns] = dataFrame[int_columns].fillna(0)\n    elif fillna == \"mean\":\n        float_columns = dataFrame.select_dtypes(include=['float']).columns\n        dataFrame[float_columns] = dataFrame[float_columns].fillna(dataFrame[float_columns].mean())\n        int_columns = dataFrame.select_dtypes(include=['int']).columns\n        dataFrame[int_columns] = dataFrame[int_columns].fillna(dataFrame[int_columns].mean())\n    else:\n        dataFrame.dropna(inplace=True)\n\n    tmp_dataFrame_day = dataFrame[\"Ngày\"]\n    tmp_dataFrame_day.reset_index(drop=True, inplace=True)\n    tmp_dataFrame_name = dataFrame[\"Tên\"]\n    tmp_dataFrame_name.reset_index(drop=True, inplace=True)\n    dataFrame.drop(columns=[\"Ngày\", \"Tên\"], inplace=True)\n    dataFrame.reset_index(drop=True, inplace=True)\n\n    if scale == \"std\":\n        scaler = MinMaxScaler()\n    else:\n        scaler = StandardScaler()\n    tmp_scaler = scaler.fit_transform(dataFrame)\n    dataFrame =  pd.DataFrame(tmp_scaler, columns=dataFrame.columns)\n    # tmp_dataFrame = pd.concat([tmp_dataFrame_day, tmp_dataFrame_name], axis=1)\n    dataFrame = pd.concat([tmp_dataFrame_day, dataFrame], axis=1)\n    dataFrame.set_index(\"Ngày\", inplace=True)\n    dataFrame.sort_values(by=\"Ngày\", inplace=True)\n    return dataFrame","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:01:54.355592Z","iopub.execute_input":"2024-06-21T14:01:54.356317Z","iopub.status.idle":"2024-06-21T14:01:54.367935Z","shell.execute_reply.started":"2024-06-21T14:01:54.356288Z","shell.execute_reply":"2024-06-21T14:01:54.367061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_process = preprocessing_dataframe(data_raw)\ndf_process.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:01:54.369059Z","iopub.execute_input":"2024-06-21T14:01:54.369427Z","iopub.status.idle":"2024-06-21T14:01:54.406214Z","shell.execute_reply.started":"2024-06-21T14:01:54.369397Z","shell.execute_reply":"2024-06-21T14:01:54.405409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data pipeline for Transformers\nHere, I am creating a model for Univariate (Auto-Regressive) Multistep Forecasting i.e. Use 'T' feature's past n value to predict 'T' feature's future k values.","metadata":{}},{"cell_type":"code","source":"# Sliding Windows for Transformers\n\n# Step parameters\nn_steps_in = 512\nn_steps_out = 24\nn_features = 1\nbatch_size = df_process.shape[0] # Only one batch containing all samples\n\n# Split data into train and test\ntrain_size = int(len(df_process) * 0.75)\ntrain_df = df_process.iloc[:train_size, 0]\ntest_df = df_process.iloc[train_size - n_steps_in:, 0].reset_index(drop = True) # Adjusting test size to account for lost steps.\n\n# I am creating sliding windows where n_steps_in time lags will form one input and predict n_steps_out time lags as output\n# In this experiment, I will be using teacher forcing strategy i.e. provide previous ground truth value at current time step of decoder input.\n\n# It requires two things:\n# 1) Inputs - Encoder Input (512 time lags) - in my case this is train_X and test_Y, \n#           - Decoder Input (24 time lags - where first lag is last input lag (acting as a start token) followed by next 23 time lags)\n# 2) Labels - Decoder Output (24 time lags) - in my case this is train_Y and test_Y\n# I need to create decoder inputs - which are train_Y_p and test_Y_p\ntrain_X = tf.keras.utils.timeseries_dataset_from_array(train_df[:-n_steps_out], None, sequence_length = n_steps_in, batch_size = batch_size)\ntrain_Y = tf.keras.utils.timeseries_dataset_from_array(train_df[n_steps_in:], None, sequence_length = n_steps_out, batch_size = batch_size)\ntrain_Y_p = tf.keras.utils.timeseries_dataset_from_array(train_df[n_steps_in-1:-1], None, sequence_length = n_steps_out, batch_size = batch_size)\ntest_X = tf.keras.utils.timeseries_dataset_from_array(test_df[:-n_steps_out], None, sequence_length = n_steps_in, batch_size = batch_size, sequence_stride = n_steps_out)\ntest_Y = tf.keras.utils.timeseries_dataset_from_array(test_df[n_steps_in:], None, sequence_length = n_steps_out, batch_size = batch_size, sequence_stride = n_steps_out)\ntest_Y_p = tf.keras.utils.timeseries_dataset_from_array(test_df[n_steps_in-1:-1], None, sequence_length = n_steps_out, batch_size = batch_size, sequence_stride = n_steps_out)\n\n# timeseries_dataset_from_array will return batch generator, I need some post processing so I will extract tensor from batches\nfor b in train_X: train_X = b\nfor b in train_Y: train_Y = b\nfor b in train_Y_p: train_Y_p = b\nfor b in test_X: test_X = b\nfor b in test_Y: test_Y = b\nfor b in test_Y_p: test_Y_p = b\n\n# Renaming and typecasting variables\ntrain_encoder_inputs = tf.expand_dims(tf.cast(train_X, dtype = tf.float32), axis = -1)\ntrain_decoder_inputs = tf.expand_dims(tf.cast(train_Y_p, dtype = tf.float32), axis = -1) \ntrain_decoder_outputs = tf.expand_dims(tf.cast(train_Y, dtype = tf.float32), axis = -1)\ntest_encoder_inputs = tf.expand_dims(tf.cast(test_X, dtype = tf.float32), axis = -1)\ntest_decoder_inputs = tf.expand_dims(tf.cast(test_Y_p, dtype = tf.float32), axis = -1)\ntest_decoder_outputs = tf.expand_dims(tf.cast(test_Y, dtype = tf.float32), axis = -1)\n\n# Verify shapes\nprint(\"Train Encoder Input: \",train_encoder_inputs.shape)\nprint(\"Train Decoder Input: \",train_decoder_inputs.shape)\nprint(\"Train Decoder Output: \",train_decoder_outputs.shape)\nprint(\"Test Encoder Input: \",test_encoder_inputs.shape)\nprint(\"Test Decoder Input: \",test_decoder_inputs.shape)\nprint(\"Test Decoder Output: \",test_decoder_outputs.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:01:54.407653Z","iopub.execute_input":"2024-06-21T14:01:54.408058Z","iopub.status.idle":"2024-06-21T14:01:58.463533Z","shell.execute_reply.started":"2024-06-21T14:01:54.408025Z","shell.execute_reply":"2024-06-21T14:01:58.462614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verify Decoder Inputs & Outputs - Outputs will be shifted one to right\nprint(train_decoder_inputs[0])\nprint(train_decoder_outputs[0])\nprint(test_decoder_inputs[0])\nprint(test_decoder_outputs[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:01:58.464692Z","iopub.execute_input":"2024-06-21T14:01:58.464976Z","iopub.status.idle":"2024-06-21T14:01:58.480457Z","shell.execute_reply.started":"2024-06-21T14:01:58.464951Z","shell.execute_reply":"2024-06-21T14:01:58.479602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transformer Model","metadata":{}},{"cell_type":"markdown","source":"#### Defining Components","metadata":{}},{"cell_type":"markdown","source":"#### Positional Encoding\nAll the input embedings are added to positional encodings before passing into the first encoder. In next experiment, I will try Time2Vec instead of Positional Encoding to encode the inputs.","metadata":{}},{"cell_type":"code","source":"# Helper function to calculate positional encoding\ndef positional_encoding(length, depth):\n    \"\"\"\n    length: width of one input i.e. number of time lags in one input sequence (n_steps_in)\n    depth: dimension of embedding i.e. number of features used to represent a single time lag (word token in NLP) - it will be 1 for our time series.\n    \n    This code is taken from tensorflow's official documentation.\n    \"\"\"\n    depth = depth / 2\n\n    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n    depths = np.arange(depth)[np.newaxis, :] / depth   # (1, depth)\n\n    angle_rates = 1 / (10000 ** depths)         # (1, depth)\n    angle_rads = positions * angle_rates      # (pos, depth)\n\n    pos_encoding = np.concatenate(\n        [np.sin(angle_rads), np.cos(angle_rads)],\n        axis = -1) \n\n    return tf.cast(pos_encoding, dtype = tf.float32)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:01:58.481501Z","iopub.execute_input":"2024-06-21T14:01:58.481774Z","iopub.status.idle":"2024-06-21T14:01:58.489004Z","shell.execute_reply.started":"2024-06-21T14:01:58.481750Z","shell.execute_reply":"2024-06-21T14:01:58.487943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PositionalEmbedding(tf.keras.layers.Layer):\n    \"\"\"\n    This code is taken from tensorflow's official documentation and modified according to requirements.\n    Instead of Embedding layer, I am using Dense layer.\n    \"\"\"\n    def __init__(self, d_model):\n        \"\"\"\n        Removed vocab_size parameter as it was used in Embedding layer and I have replaced that with Dense.\n        \"\"\"\n        super().__init__()\n        self.d_model = d_model\n        self.embedding = tf.keras.layers.Dense(units = d_model) \n        self.pos_encoding = positional_encoding(length = 512, depth = d_model)\n\n    def compute_mask(self, *args, **kwargs):\n        return self.embedding.compute_mask(*args, **kwargs)\n\n    def call(self, x):\n        length = tf.shape(x)[1]\n        x = self.embedding(x)\n        # This factor sets the relative scale of the embedding and positonal_encoding.\n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        x = x + self.pos_encoding[tf.newaxis, :length, :]\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:01:58.490172Z","iopub.execute_input":"2024-06-21T14:01:58.490469Z","iopub.status.idle":"2024-06-21T14:01:58.498878Z","shell.execute_reply.started":"2024-06-21T14:01:58.490438Z","shell.execute_reply":"2024-06-21T14:01:58.498169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test PositionalEmbedding layer\nembed_enc = PositionalEmbedding(d_model = 64)\nembed_dec = PositionalEmbedding(d_model = 64)\n\nec = embed_enc(train_encoder_inputs[0])\ndc = embed_dec(train_decoder_inputs[0])\n\nprint(ec.shape)\nprint(dc.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:01:58.502470Z","iopub.execute_input":"2024-06-21T14:01:58.502784Z","iopub.status.idle":"2024-06-21T14:02:00.578740Z","shell.execute_reply.started":"2024-06-21T14:01:58.502762Z","shell.execute_reply":"2024-06-21T14:02:00.577770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Time2Vec Layer\nReplacement for positional embedding. The aim of Time2Vec is to learn a feature representation (embedding) for time series data.","metadata":{}},{"cell_type":"code","source":"class Time2Vec(tf.keras.layers.Layer):\n    def __init__(self, d_model, **kwargs):\n        self.output_dim = d_model - 1\n        super(Time2Vec, self).__init__(**kwargs)\n    \n    def build(self, input_shape):\n        self.W = self.add_weight(name = 'W',\n                      shape = (input_shape[-1], self.output_dim),\n                      initializer = 'uniform',\n                      trainable = True)\n        self.P = self.add_weight(name = 'P',\n                      shape = (input_shape[1], self.output_dim),\n                      initializer = 'uniform',\n                      trainable = True)\n        self.w = self.add_weight(name = 'w',\n                      shape = (input_shape[1], 1),\n                      initializer = 'uniform',\n                      trainable = True)\n        self.p = self.add_weight(name = 'p',\n                      shape = (input_shape[1], 1),\n                      initializer = 'uniform',\n                      trainable = True)\n        super(Time2Vec, self).build(input_shape)\n    \n    def call(self, x):\n        original = self.w * x + self.p\n        sin_trans = tf.math.sin(tf.tensordot(x, self.W, axes = 1) + self.P)\n        \n        return tf.concat([sin_trans, original], -1)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.579867Z","iopub.execute_input":"2024-06-21T14:02:00.580154Z","iopub.status.idle":"2024-06-21T14:02:00.589576Z","shell.execute_reply.started":"2024-06-21T14:02:00.580118Z","shell.execute_reply":"2024-06-21T14:02:00.588724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing Time2Vec Layer\nembed_enc = Time2Vec(d_model = 4)\nembed_dec = Time2Vec(d_model = 4)\n\nec = embed_enc(train_encoder_inputs[0:10])\ndc = embed_dec(train_decoder_inputs[0:10])\n\nprint(ec.shape)\nprint(dc.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.590828Z","iopub.execute_input":"2024-06-21T14:02:00.591132Z","iopub.status.idle":"2024-06-21T14:02:00.640174Z","shell.execute_reply.started":"2024-06-21T14:02:00.591109Z","shell.execute_reply":"2024-06-21T14:02:00.639388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Base Attention Layer\nActs as super class for all attention layers in encoder and decoder.","metadata":{}},{"cell_type":"code","source":"class BaseAttention(tf.keras.layers.Layer):\n    \"\"\"\n    This code is taken from tensorflow's official documentation.\n    \"\"\"\n    def __init__(self, **kwargs):\n        super().__init__()\n        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n        self.layernorm = tf.keras.layers.LayerNormalization()\n        self.add = tf.keras.layers.Add()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.641317Z","iopub.execute_input":"2024-06-21T14:02:00.641569Z","iopub.status.idle":"2024-06-21T14:02:00.646912Z","shell.execute_reply.started":"2024-06-21T14:02:00.641548Z","shell.execute_reply":"2024-06-21T14:02:00.645923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cross Attention\nEncoder-Decoder Attention in the Decoder block.","metadata":{}},{"cell_type":"code","source":"class CrossAttention(BaseAttention):\n    \"\"\"\n    This code is taken from tensorflow's official documentation.\n    \"\"\"\n    def call(self, x, context):\n        attn_output, attn_scores = self.mha(\n            query = x,\n            key = context,\n            value = context,\n            return_attention_scores = True)\n\n        # Cache the attention scores for plotting later.\n        self.last_attn_scores = attn_scores\n\n        x = self.add([x, attn_output])\n        x = self.layernorm(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.648251Z","iopub.execute_input":"2024-06-21T14:02:00.648545Z","iopub.status.idle":"2024-06-21T14:02:00.657326Z","shell.execute_reply.started":"2024-06-21T14:02:00.648523Z","shell.execute_reply":"2024-06-21T14:02:00.656523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing CrossAttention layer\nsample_ca = CrossAttention(num_heads = 2, key_dim = 8)\n\nprint(ec.shape)\nprint(dc.shape)\nprint(sample_ca(dc, ec).shape) # Pass x first (decoder input), then context (output received from  last encoder layer)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.658445Z","iopub.execute_input":"2024-06-21T14:02:00.658792Z","iopub.status.idle":"2024-06-21T14:02:00.794456Z","shell.execute_reply.started":"2024-06-21T14:02:00.658768Z","shell.execute_reply":"2024-06-21T14:02:00.793385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Global Self Attention Layer\nAttention layer used in encoder layers.","metadata":{}},{"cell_type":"code","source":"class GlobalSelfAttention(BaseAttention):\n    \"\"\"\n    This code is taken from tensorflow's official documentation.\n    \"\"\"\n    def call(self, x):\n        attn_output = self.mha(\n            query = x,\n            value = x,\n            key = x)\n        x = self.add([x, attn_output])\n        x = self.layernorm(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.795691Z","iopub.execute_input":"2024-06-21T14:02:00.795968Z","iopub.status.idle":"2024-06-21T14:02:00.801345Z","shell.execute_reply.started":"2024-06-21T14:02:00.795944Z","shell.execute_reply":"2024-06-21T14:02:00.800420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing GlobalSelfAttention layer\nsample_gsa = GlobalSelfAttention(num_heads = 3, key_dim = 8)\n\nprint(ec.shape)\nprint(sample_gsa(ec).shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.802905Z","iopub.execute_input":"2024-06-21T14:02:00.803195Z","iopub.status.idle":"2024-06-21T14:02:00.846746Z","shell.execute_reply.started":"2024-06-21T14:02:00.803165Z","shell.execute_reply":"2024-06-21T14:02:00.845988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Causal Self Attention Layer\nSelf Attention layer used in Decoder which is only applied on the initial decoder inputs / outputs of previous decoder layer. The one which requires masking of next time lags.","metadata":{}},{"cell_type":"code","source":"class CausalSelfAttention(BaseAttention):\n    \"\"\"\n    This code is taken from tensorflow's official documentation.\n    \"\"\"\n    def call(self, x):\n        attn_output = self.mha(\n            query = x,\n            value = x,\n            key = x,\n            use_causal_mask = True)\n        x = self.add([x, attn_output])\n        x = self.layernorm(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.847805Z","iopub.execute_input":"2024-06-21T14:02:00.848054Z","iopub.status.idle":"2024-06-21T14:02:00.853735Z","shell.execute_reply.started":"2024-06-21T14:02:00.848033Z","shell.execute_reply":"2024-06-21T14:02:00.852867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing CausalSelfAttention layer\nsample_csa = CausalSelfAttention(num_heads = 2, key_dim = 8)\n\nprint(dc.shape)\nprint(sample_csa(dc).shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.854760Z","iopub.execute_input":"2024-06-21T14:02:00.855043Z","iopub.status.idle":"2024-06-21T14:02:00.902149Z","shell.execute_reply.started":"2024-06-21T14:02:00.855021Z","shell.execute_reply":"2024-06-21T14:02:00.901306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feed Forward Layer\nUsed in both encoder and decoder layers.","metadata":{}},{"cell_type":"code","source":"class FeedForward(tf.keras.layers.Layer):\n    \"\"\"\n    This code is taken from tensorflow's official documentation.\n    \"\"\"\n    def __init__(self, d_model, dff, dropout_rate = 0.1):\n        super().__init__()\n        self.seq = tf.keras.Sequential([\n              tf.keras.layers.Dense(dff, activation = 'relu'),\n              tf.keras.layers.Dense(d_model),\n              tf.keras.layers.Dropout(dropout_rate)\n            ])\n        self.add = tf.keras.layers.Add()\n        self.layer_norm = tf.keras.layers.LayerNormalization()\n\n    def call(self, x):\n        x = self.add([x, self.seq(x)])\n        x = self.layer_norm(x) \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.903198Z","iopub.execute_input":"2024-06-21T14:02:00.903458Z","iopub.status.idle":"2024-06-21T14:02:00.909859Z","shell.execute_reply.started":"2024-06-21T14:02:00.903436Z","shell.execute_reply":"2024-06-21T14:02:00.909005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing FeedForward layer\nsample_ff = FeedForward(d_model = 4, dff = 2048)\n\nprint(ec.shape)\nprint(sample_ff(ec).shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.911041Z","iopub.execute_input":"2024-06-21T14:02:00.911869Z","iopub.status.idle":"2024-06-21T14:02:00.977974Z","shell.execute_reply.started":"2024-06-21T14:02:00.911839Z","shell.execute_reply":"2024-06-21T14:02:00.977002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Encoder Layer\nA single encder layer","metadata":{}},{"cell_type":"code","source":"class EncoderLayer(tf.keras.layers.Layer):\n    \"\"\"\n    This code is taken from tensorflow's official documentation.\n    \"\"\"\n    def __init__(self,*, d_model, num_heads, dff, dropout_rate = 0.1):\n        super().__init__()\n        self.self_attention = GlobalSelfAttention(num_heads = num_heads, key_dim = d_model, dropout = dropout_rate)\n        self.ffn = FeedForward(d_model, dff)\n\n    def call(self, x):\n        x = self.self_attention(x)\n        x = self.ffn(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.979314Z","iopub.execute_input":"2024-06-21T14:02:00.979676Z","iopub.status.idle":"2024-06-21T14:02:00.986612Z","shell.execute_reply.started":"2024-06-21T14:02:00.979642Z","shell.execute_reply":"2024-06-21T14:02:00.985718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing EncoderLayer layer\nsample_el = EncoderLayer(d_model = 4, num_heads = 2, dff = 2048)\n\nprint(ec.shape)\nprint(sample_el(ec).shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:00.987865Z","iopub.execute_input":"2024-06-21T14:02:00.988147Z","iopub.status.idle":"2024-06-21T14:02:01.074537Z","shell.execute_reply.started":"2024-06-21T14:02:00.988107Z","shell.execute_reply":"2024-06-21T14:02:01.073608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The Encoder\nEncoder consisting of multiple encoder layers and the positional embedding layer","metadata":{}},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer):\n    \"\"\"\n    This code is taken from tensorflow's official documentation and modified according to requirements.\n    \"\"\"\n    def __init__(self, *, num_layers, d_model, num_heads, dff, dropout_rate = 0.1):\n        \"\"\"\n        Removed vocab_size parameter.\n        \"\"\"\n        super().__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n        self.pos_embedding = Time2Vec(d_model = d_model)\n        self.enc_layers = [EncoderLayer(d_model = d_model, num_heads = num_heads, dff = dff, dropout_rate = dropout_rate) for _ in range(num_layers)]\n        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n\n    def call(self, x):\n        # `x` is token-IDs shape: (batch, seq_len)\n        x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n\n        # Add dropout.\n        x = self.dropout(x)\n        \n        for i in range(self.num_layers):\n            x = self.enc_layers[i](x)\n\n        return x  # Shape `(batch_size, seq_len, d_model)`.","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:01.075667Z","iopub.execute_input":"2024-06-21T14:02:01.075956Z","iopub.status.idle":"2024-06-21T14:02:01.083854Z","shell.execute_reply.started":"2024-06-21T14:02:01.075931Z","shell.execute_reply":"2024-06-21T14:02:01.082979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing Encoder \nsample_ec = Encoder(num_layers = 2, d_model = 4, num_heads = 4, dff = 2048)\n\nprint(train_encoder_inputs[0:10].shape)\nprint(sample_ec(train_encoder_inputs[0:10], training = False).shape) #Expected op - (batch_size, n_steps_in, d_model) or same as encoder inputs.","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:01.085256Z","iopub.execute_input":"2024-06-21T14:02:01.085834Z","iopub.status.idle":"2024-06-21T14:02:01.245736Z","shell.execute_reply.started":"2024-06-21T14:02:01.085800Z","shell.execute_reply":"2024-06-21T14:02:01.244802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Decoder Layer\nA single decoder layer","metadata":{}},{"cell_type":"code","source":"class DecoderLayer(tf.keras.layers.Layer):\n    \"\"\"\n    This code is taken from tensorflow's official documentation.\n    \"\"\"\n    def __init__(self, *, d_model, num_heads, dff, dropout_rate = 0.1):\n        super(DecoderLayer, self).__init__()\n        self.causal_self_attention = CausalSelfAttention(num_heads = num_heads, key_dim = d_model, dropout = dropout_rate)\n        self.cross_attention = CrossAttention(num_heads = num_heads, key_dim = d_model, dropout = dropout_rate)\n        self.ffn = FeedForward(d_model, dff)\n\n    def call(self, x, context):\n        x = self.causal_self_attention(x=x)\n        x = self.cross_attention(x=x, context=context)\n\n        # Cache the last attention scores for plotting later\n        self.last_attn_scores = self.cross_attention.last_attn_scores\n\n        x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:01.246834Z","iopub.execute_input":"2024-06-21T14:02:01.247095Z","iopub.status.idle":"2024-06-21T14:02:01.254247Z","shell.execute_reply.started":"2024-06-21T14:02:01.247072Z","shell.execute_reply":"2024-06-21T14:02:01.253183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing DecoderLayer layer\nsample_dl = DecoderLayer(d_model = 4, num_heads = 3, dff = 2048)\n\nec_o = sample_ec(train_encoder_inputs[0:10], training = False)\nprint(ec_o.shape)\nprint(dc.shape)\n\nprint(sample_dl(dc, ec_o).shape) # Shape (batch_size, n_steps_out, d_model) or same as decoder inputs.","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:01.255474Z","iopub.execute_input":"2024-06-21T14:02:01.255758Z","iopub.status.idle":"2024-06-21T14:02:01.404302Z","shell.execute_reply.started":"2024-06-21T14:02:01.255735Z","shell.execute_reply":"2024-06-21T14:02:01.403322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The Decoder\nDecoder consisting of multiple decoder layers and positional embedding layer.","metadata":{}},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer):\n    \"\"\"\n    This code is taken from tensorflow's official documentation and modified according to requirements.\n    \"\"\"\n    def __init__(self, *, num_layers, d_model, num_heads, dff, dropout_rate = 0.1):\n        \"\"\"\n        Removed vocab_size parameter.\n        \"\"\"\n        super(Decoder, self).__init__()\n        self.d_model = d_model\n        self.num_layers = num_layers\n        self.pos_embedding = PositionalEmbedding(d_model = d_model)\n        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n        self.dec_layers = [DecoderLayer(d_model = d_model, num_heads = num_heads,dff = dff, dropout_rate = dropout_rate) for _ in range(num_layers)]\n        self.last_attn_scores = None\n\n    def call(self, x, context):\n        # `x` is token-IDs shape (batch, target_seq_len)\n        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n\n        x = self.dropout(x)\n\n        for i in range(self.num_layers):\n            x  = self.dec_layers[i](x, context)\n\n        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n\n        # The shape of x is (batch_size, target_seq_len, d_model).\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:01.408717Z","iopub.execute_input":"2024-06-21T14:02:01.408964Z","iopub.status.idle":"2024-06-21T14:02:01.417265Z","shell.execute_reply.started":"2024-06-21T14:02:01.408943Z","shell.execute_reply":"2024-06-21T14:02:01.416403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing Decoder\nsample_dc = Decoder(num_layers = 2, d_model = 4, num_heads = 3, dff = 2048)\n\nec_o = sample_ec(train_encoder_inputs[0:10], training = False)\nprint(ec_o.shape)\n\nprint(train_decoder_inputs[0:10].shape)\nprint(sample_dc(train_decoder_inputs[0:10], ec_o).shape) # Same as train_decoder_outputs or (batch_size, n_steps_out, d_model)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:01.418639Z","iopub.execute_input":"2024-06-21T14:02:01.418913Z","iopub.status.idle":"2024-06-21T14:02:01.896311Z","shell.execute_reply.started":"2024-06-21T14:02:01.418882Z","shell.execute_reply":"2024-06-21T14:02:01.895183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The Transformer","metadata":{}},{"cell_type":"code","source":"class Transformer(tf.keras.Model):\n    \"\"\"\n    This code is taken from tensorflow's official documentation and modified according to requirements.\n    \"\"\"\n    def __init__(self, *, num_layers, d_model, num_heads, dff, n_features, n_steps_out, dropout_rate = 0.1):\n        \"\"\"\n        Removed input_vocab_size and output_vocab_size parameters, added n_features parameter for final dense layer and n_steps_out for inference loop.\n        \"\"\"\n        super().__init__()\n        self.encoder = Encoder(num_layers = num_layers, d_model = d_model, num_heads = num_heads, dff = dff, dropout_rate = dropout_rate)\n        self.decoder = Decoder(num_layers = num_layers, d_model = d_model, num_heads = num_heads, dff = dff, dropout_rate = dropout_rate)\n        self.final_layer = tf.keras.layers.Dense(n_features)\n\n    def call(self, inputs):\n        # To use a Keras model with `.fit` you must pass all your inputs in the\n        # first argument.\n        context, x  = inputs\n\n        context = self.encoder(context)  # (batch_size, context_len, d_model)\n\n        x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n\n        # Final linear layer output.\n        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n\n        try:\n            # Drop the keras mask, so it doesn't scale the losses/metrics.\n            del logits._keras_mask\n        except AttributeError:\n            pass\n\n        # Return the final output and the attention weights.\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:01.897432Z","iopub.execute_input":"2024-06-21T14:02:01.897723Z","iopub.status.idle":"2024-06-21T14:02:01.907151Z","shell.execute_reply.started":"2024-06-21T14:02:01.897690Z","shell.execute_reply":"2024-06-21T14:02:01.906159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing the Transformer\ntrf = Transformer(num_layers = 2, d_model = 4, num_heads = 3, dff = 1024, n_features = n_features, n_steps_out = n_steps_out)\n\ninp = (train_encoder_inputs[0:10], train_decoder_inputs[0:10])\ntrf_op = trf(inp)\ntrf_op.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:01.908585Z","iopub.execute_input":"2024-06-21T14:02:01.908924Z","iopub.status.idle":"2024-06-21T14:02:02.303954Z","shell.execute_reply.started":"2024-06-21T14:02:01.908896Z","shell.execute_reply":"2024-06-21T14:02:02.303005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Transforecaster","metadata":{}},{"cell_type":"code","source":"# Custom LR Scheduler as per Attention is all you need paper\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    \"\"\"\n    This code is taken from tensorflow's official documentation.\n    \"\"\"\n    def __init__(self, d_model, warmup_steps = 760):\n        super().__init__()\n        self.d_model = d_model\n        self.d_model = tf.cast(self.d_model, tf.float32)\n        self.warmup_steps = warmup_steps\n\n    def __call__(self, step):\n        step = tf.cast(step, dtype=tf.float32)\n        arg1 = tf.math.rsqrt(step)\n        arg2 = step * (self.warmup_steps ** -1.5)\n        \n        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:02.304876Z","iopub.execute_input":"2024-06-21T14:02:02.305127Z","iopub.status.idle":"2024-06-21T14:02:02.312031Z","shell.execute_reply.started":"2024-06-21T14:02:02.305105Z","shell.execute_reply":"2024-06-21T14:02:02.311160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Hyperparameters\nnum_layers = 4\nd_model = 128\nnum_heads = 7\ndff = 1024\ndropout_rate = 0.4\n\n# Define Model\ntransforecaster = Transformer(\n    num_layers = num_layers, \n    d_model = d_model, \n    num_heads = num_heads, \n    dff = dff, \n    n_features = n_features, \n    n_steps_out = n_steps_out,\n    dropout_rate = dropout_rate\n)\n\n# Test and check no. of parameters\ninp = (train_encoder_inputs[0:128], train_decoder_inputs[0:128])\nprint(\"Decoder O/P Shape: \",transforecaster(inp).shape, \"\\n\")\ntransforecaster.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:02.313092Z","iopub.execute_input":"2024-06-21T14:02:02.313405Z","iopub.status.idle":"2024-06-21T14:02:03.482780Z","shell.execute_reply.started":"2024-06-21T14:02:02.313381Z","shell.execute_reply":"2024-06-21T14:02:03.481846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = CustomSchedule(d_model)\noptimizer = tf.keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n\nplt.plot(learning_rate(tf.range(8000, dtype = tf.float32)))\nplt.ylabel('Learning Rate')\nplt.xlabel('Train Step')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:02:03.484012Z","iopub.execute_input":"2024-06-21T14:02:03.484393Z","iopub.status.idle":"2024-06-21T14:02:03.809932Z","shell.execute_reply.started":"2024-06-21T14:02:03.484359Z","shell.execute_reply":"2024-06-21T14:02:03.809093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile and Train\ntransforecaster.compile(\n    loss='mean_squared_error',\n    optimizer=optimizer,\n    metrics=[\n        tf.keras.metrics.MeanAbsoluteError(name='mae'),\n        tf.keras.losses.Huber(name='huber_loss')\n    ]\n)\n\ntransforecaster.fit(\n    x=(train_encoder_inputs, train_decoder_inputs),\n    y=train_decoder_outputs,\n    batch_size=64,\n    epochs=100\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:13:04.615742Z","iopub.execute_input":"2024-06-21T14:13:04.616078Z","iopub.status.idle":"2024-06-21T14:34:14.563594Z","shell.execute_reply.started":"2024-06-21T14:13:04.616053Z","shell.execute_reply":"2024-06-21T14:34:14.562693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate model\nresults = transforecaster.evaluate(\n    x=(test_encoder_inputs, test_decoder_inputs),\n    y=test_decoder_outputs,\n    batch_size=64\n)\n\nprint(\"Test Loss (MSE):\", results[0])\nprint(\"Test MAE:\", results[1])\nprint(\"Test Huber Loss:\", results[2])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T14:37:51.053834Z","iopub.execute_input":"2024-06-21T14:37:51.054185Z","iopub.status.idle":"2024-06-21T14:37:51.450845Z","shell.execute_reply.started":"2024-06-21T14:37:51.054157Z","shell.execute_reply":"2024-06-21T14:37:51.449351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}