
[1/300: TRAINING PHASE]

 64%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 47/73 [00:03<00:01, 14.58it/s, Loss_Train=0.0306]
[RESULT TRAINING PHASE]: Loss Train: 0.18539256714794733
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [00:05<00:00, 13.37it/s, Loss_Train=0.124]


 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 60/73 [00:04<00:00, 14.52it/s, Loss_Train=0.0206]
[RESULT TRAINING PHASE]: Loss Train: 0.06975116345980396
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [00:05<00:00, 14.54it/s, Loss_Train=0.114]

 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 50/73 [00:03<00:01, 14.50it/s, Loss_Train=0.0303]
[RESULT TRAINING PHASE]: Loss Train: 0.1261403930998624
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [00:05<00:00, 14.54it/s, Loss_Train=0.0482]


 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 64/73 [00:04<00:00, 14.49it/s, Loss_Train=0.0737]
[RESULT TRAINING PHASE]: Loss Train: 0.06338407404159438
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [00:05<00:00, 14.51it/s, Loss_Train=0.0403]
  0%|                                                                                                                                                                                       | 0/19 [00:00<?, ?it/s]c:\Users\Cong\.conda\envs\idm\lib\site-packages\torch\nn\modules\activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\attention.cpp:152.)
  return torch._native_multi_head_attention(
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 15/19 [00:01<00:00, 14.09it/s]
[RESULT VALIDATION PHASE]: MSE: 0.08216177076591473 | MAE: 0.23615936758486847 | HUBER: 0.041080885382957365

